# ğŸ§¾ GPTDevTeam - Ficha TÃ©cnica

## ğŸ§  DescripciÃ³n General

**Juanito Software 2025** es un sistema automatizado de generaciÃ³n, validaciÃ³n, ejecuciÃ³n y documentaciÃ³n de cÃ³digo Python utilizando modelos de lenguaje basados en LLMs como **CodeLlama-GPTQ** y **CodeGemma**. EstÃ¡ diseÃ±ado para crear scripts funcionales, corregir errores automÃ¡ticamente, validar su ejecuciÃ³n y documentar el cÃ³digo generado.

## ğŸ‘¨â€ğŸ’» Desarrollador

**GPTDevTeam**

---

## ğŸ§± Componentes Principales

- **CodeLlama-7B-GPTQ**: Modelo LLM cuantizado para generaciÃ³n de cÃ³digo.
- **CodeGemma (Ollama)**: LLM para documentaciÃ³n automÃ¡tica vÃ­a API local.
- **Transformers** (HuggingFace): TokenizaciÃ³n y manipulaciÃ³n del modelo.
- **Triton / Torch / CUDA**: Infraestructura para ejecuciÃ³n en GPU.
- **Subprocess / threading**: Control de ejecuciÃ³n del cÃ³digo generado.

---

## âš™ï¸ Requisitos del Sistema

### Dependencias de Python:

```bash
transformers
torch
triton
requests
textwrap
huggingface_hub
```

### Requisitos del sistema:

- Python 3.8+
- GPU compatible con CUDA
- [Ollama](https://ollama.com/) corriendo localmente en `localhost:11434`
- Memoria recomendada: 16 GB RAM / 12 GB VRAM
- Acceso a internet (opcional, si se usan modelos locales ya descargados)

---

## ğŸ§© Estructura del Programa

- `main()`: Orquestador general del flujo de trabajo.
- `codellama_generate(prompt)`: GeneraciÃ³n de cÃ³digo a partir de una instrucciÃ³n.
- `build_codellama_prompt(code)`: GeneraciÃ³n de prompts de refactorizaciÃ³n.
- `ejecutar_codigo_py(path)`: Ejecuta el cÃ³digo generado y verifica su funcionamiento.
- `extraer_codigo_puro(texto)`: Limpia la salida de los LLMs para extraer solo el cÃ³digo.
- `documentar_codigo(codigo)`: Usa CodeGemma para comentar el cÃ³digo.
- `limpiar_docstring_inicial(codigo)`: Elimina docstrings incorrectos o mal formateados.

---

## ğŸ” Flujo de EjecuciÃ³n

1. Se genera un script Python a partir de una descripciÃ³n en lenguaje natural.
2. El cÃ³digo se limpia y formatea.
3. Se corrige iterativamente con un mÃ¡ximo de 4 intentos si contiene errores.
4. Se ejecuta en tiempo real y se monitorea por errores.
5. Si la ejecuciÃ³n es exitosa, se documenta automÃ¡ticamente.
6. El cÃ³digo final se guarda como `CodigoFinal.py`.

---

## ğŸ“¦ Salidas

- `codigo_actual.py`: CÃ³digo intermedio a ejecutar/testear.
- `CodigoFinal.py`: CÃ³digo funcional y documentado.
- Logs en consola: estado de cada intento de ejecuciÃ³n y errores detectados.

---

## ğŸ›¡ï¸ ValidaciÃ³n de EjecuciÃ³n

El cÃ³digo generado se ejecuta automÃ¡ticamente. Si contiene errores, se depura con ayuda del propio modelo, reutilizando el mensaje de error como parte del nuevo prompt.

---

## ğŸŒ Conectividad

- Ollama debe estar corriendo localmente.
- El modelo "codegemma:7b-instruct" debe estar disponible para generar documentaciÃ³n.

---

## ğŸ“š Licencias y CrÃ©ditos

- Modelos LLM proporcionados por [TheBloke](https://huggingface.co/TheBloke) y [Google](https://github.com/google/codegemma).
- Uso de Transformers y HuggingFace Hub bajo licencia Apache 2.0.
- Este software es de uso experimental/educativo y no garantiza cÃ³digo seguro en entornos de producciÃ³n.

---

## ğŸ EjecuciÃ³n

```bash
python main.py
```

---

## ğŸš¨ Notas de Seguridad

- **No ejecutar el cÃ³digo generado sin revisiÃ³n manual previa en entornos sensibles.**
- **El sistema puede generar cÃ³digo no seguro si el prompt lo induce.**

---

## ğŸ“ƒ Licencia

Este programa es software libre: puedes redistribuirlo y/o modificarlo bajo los tÃ©rminos de la Licencia PÃºblica General de GNU, versiÃ³n 3 o cualquier versiÃ³n posterior.

Consulta la licencia completa para mÃ¡s detalles.
MÃ¡s informaciÃ³n: [https://www.gnu.org/licenses/gpl-3.0.html](https://www.gnu.org/licenses/gpl-3.0.html)

Â© 2025 JuanitoSoftware

---

## ğŸ“¬ Contacto

ğŸ“§ bernaldezperedaj@gmail.com
